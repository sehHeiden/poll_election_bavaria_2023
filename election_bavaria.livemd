# Bavarian Election

```elixir
Mix.install(
  [
    {:bumblebee, "~> 0.3"},
    {:explorer, "~> 0.7"},
    {:kino_vega_lite, "~> 0.1.7"},
    {:httpoison, "~> 1.8"},
    {:kino_bumblebee, "~> 0.3.0"},
    {:exla, "~> 0.5.1"},
    {:axon_onnx, "~> 0.4"},
    {:kino_db, "~> 0.2.1"},
    {:adbc, "~> 0.1"}
  ],
  config: [
    nx: [default_backend: EXLA.Backend]
  ]
)
```

## Polls

```elixir
alias VegaLite, as: Vl
```

```elixir
polls = Explorer.DataFrame.from_csv!("polls.csv")
```

```elixir
defmodule Graphs do
  def create_graph(data_source, title, party) do
    Vl.new(width: 500, height: 300, title: title)
    |> Vl.data_from_values(data_source, only: ["end_date", party, "institute"])
    |> Vl.layers([
      Vl.new()
      |> Vl.mark(:point)
      |> Vl.encode_field(:x, "end_date", type: :temporal, title: "poll end date")
      |> Vl.encode_field(:y, party, type: :quantitative, title: "percentage")
      |> Vl.encode_field(:color, "institute", type: :nominal),
      Vl.new()
      |> Vl.mark(:line, color: "firebrick", opacity: 0.5)
      |> Vl.transform(regression: party, on: "end_date")
      |> Vl.encode_field(:x, "end_date", type: :temporal, title: "poll end date")
      |> Vl.encode_field(:y, party, type: :quantitative, title: "percentage")
    ])
  end
end
```

```elixir
Graphs.create_graph(polls, "Polls - CSU", "csu")
```

```elixir
Graphs.create_graph(polls, "Polls - Buendnis-Gruene", "gruene")
```

```elixir
Graphs.create_graph(polls, "Polls - Freie Waehler", "fw")
```

```elixir
Graphs.create_graph(polls, "Polls - AFD", "afd")
```

```elixir
Graphs.create_graph(polls, "Polls - SPD", "spd")
```

```elixir
Graphs.create_graph(polls, "Polls - FDP", "fdp")
```

```elixir
Graphs.create_graph(polls, "Polls - Linke", "linke")
```

## Party

```elixir
parties_df =
  Explorer.DataFrame.new(
    party: ["csu", "fw", "spd", "gruene", "fdp", "afd", "linke"],
    candiate1: [
      "Markus Söder",
      "Hubert Aiwanger",
      "Florian von Brunn",
      "Ludwig Hartmann",
      "Martin Hagen",
      "Katrin Ebner-Steiner",
      "Adelheid Rupp"
    ],
    candidate2: [nil, nil, nil, "Katharina Schulze", nil, "Martin Böhm", nil]
  )

Explorer.DataFrame.head(parties_df)
```

## Preprocessing posts for sentiment analysis

Before the sentiments can be read from the posts. It is nessescary to remove html tags.
The mastodon tags, need to be converted to text.

```elixir
f = "./mastodon/mastodon_bayernwahl2023.db"
p = Path.absname(f)
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
Adbc.download_driver!(:sqlite)
{:ok, db} = Kino.start_child({Adbc.Database, driver: :sqlite, uri: p})

{:ok, conn} = Kino.start_child({Adbc.Connection, database: db})
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
{:ok, toots_df} = Explorer.DataFrame.from_query(conn, "select * from toots", [])
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
posts =
  toots_df[:content]
  |> Explorer.Series.to_list()

# r = ~r/ https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{2,256}\.[a-z]{2,6}\b([-a-zA-Z0-9@:%_\+.~#?&\/\/=]*)/
r =
  Regex.compile!(
    "<[^>]*>|#|https?:\/\/(?:www\.)?([-a-zA-Z0-9@:%._\+~#=]{2,256}\.[a-z]{2,6}\b)*(\/[\/\d\w\.-]*)*(?:[\?])*(.+)*|="
  )

cleared_posts = Enum.map(posts, &Regex.replace(r, &1, ""))

r =
  Regex.compile!(
    "https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{2,256}\.[a-z]{2,6}\b([-a-zA-Z0-9@:%_\+.~#?&\/\/=]*)"
  )

cleared_posts = Enum.map(cleared_posts, &Regex.replace(r, &1, ""))
```

## Classification

Before the sentiment analysis. The langauage has to be checked. As the language attribute is very often not correct.
Therefore a language detection has to be made first with **XLM-RoBERTa - language detection**.
Than the german text are evaluated with **german-sentiment_bert**.

English texts with **RoBERTa (BERTtweet) - Sentiment**.

### language detection

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "papluca/xlm-roberta-base-language-detection"})

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "papluca/xlm-roberta-base-language-detection"})

serving =
  Bumblebee.Text.text_classification(model_info, tokenizer,
    compile: [batch_size: length(cleared_posts), sequence_length: 100],
    defn_options: [compiler: EXLA]
  )
```

```elixir
p = Nx.Serving.run(serving, cleared_posts)
```

```elixir
languages =
  Enum.map(p, fn post ->
    post
    |> Enum.at(0)
    |> elem(1)
    |> Enum.at(0)
    |> (& &1[:label]).()
  end)
```

```elixir
Enum.frequencies(languages)
```

### German Sentiments

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "oliverguhr/german-sentiment-bert"})
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "bert-base-german-cased"})
```

```elixir
serving =
  Bumblebee.Text.text_classification(model_info, tokenizer, defn_options: [compiler: EXLA])

texts = [
  "Entnazifizierung in Kaltland: Beantworten Sie 25 Fragen und Sie dürfen alle Ihre Ämter und Verantwortlichkeiten behalten aiwanger bayern csu",
  "Das ist gar nicht mal so gut",
  "Total awesome!",
  "nicht so schlecht wie erwartet",
  "Der Test verlief positiv.",
  "Sie fährt ein grünes Auto.",
  "So ein scheiß Film."
]

Nx.Serving.run(serving, texts)
```

### Englisch Sentiment

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "finiteautomata/bertweet-base-sentiment-analysis"})

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "vinai/bertweet-base"})

serving =
  Bumblebee.Text.text_classification(model_info, tokenizer,
    compile: [batch_size: 1, sequence_length: 100],
    defn_options: [compiler: EXLA]
  )
```

```elixir
text_input = Kino.Input.textarea("Text", default: "Cats are so cute")
form = Kino.Control.form([text: text_input], submit: "Run")
frame = Kino.Frame.new()

Kino.listen(form, fn %{data: %{text: text}} ->
  Kino.Frame.render(frame, Kino.Text.new("Running..."))
  output = Nx.Serving.run(serving, text)

  output.predictions
  |> Enum.map(&{&1.label, &1.score})
  |> Kino.Bumblebee.ScoredList.new()
  |> then(&Kino.Frame.render(frame, &1))
end)

Kino.Layout.grid([form, frame], boxed: true, gap: 16)
```
