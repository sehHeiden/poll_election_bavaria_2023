# Bavarian Election

```elixir
Mix.install(
  [
    {:explorer, "~> 0.7"},
    {:kino_vega_lite, "~> 0.1.7"},
    {:httpoison, "~> 1.8"},
    {:kino_bumblebee, "~> 0.3.0"},
    {:exla, "~> 0.5.1"},
    {:axon_onnx, "~> 0.4"},
    {:kino_db, "~> 0.2.1"},
    {:adbc, "~> 0.1"}
  ],
  config: [
    nx: [default_backend: EXLA.Backend]
  ]
)
```

## Polls

```elixir
alias VegaLite, as: Vl
```

```elixir
pools = Explorer.DataFrame.from_csv!("polls.csv")
```

```elixir
defmodule Graphs do
  def create_graph(data_source, title, party) do
    Vl.new(width: 500, height: 300, title: title)
    |> Vl.data_from_values(data_source, only: ["end_date", party, "institute"])
    |> Vl.layers([
      Vl.new()
      |> Vl.mark(:point)
      |> Vl.encode_field(:x, "end_date", type: :temporal, title: "poll end date")
      |> Vl.encode_field(:y, party, type: :quantitative, title: "percentage")
      |> Vl.encode_field(:color, "institute", type: :nominal),
      Vl.new()
      |> Vl.mark(:line, color: "firebrick", opacity: 0.5)
      |> Vl.transform(regression: party, on: "end_date")
      |> Vl.encode_field(:x, "end_date", type: :temporal, title: "poll end date")
      |> Vl.encode_field(:y, party, type: :quantitative, title: "percentage")
    ])
  end
end
```

```elixir
Graphs.create_graph(pools, "Polls - CSU", "csu")
```

```elixir
Graphs.create_graph(pools, "Pools - Buendnis-Gruene", "gruene")
```

```elixir
Graphs.create_graph(pools, "Pools - Freie Waehler", "fw")
```

```elixir
Graphs.create_graph(pools, "Pools - AFD", "afd")
```

```elixir
Graphs.create_graph(pools, "Pools - SPD", "spd")
```

```elixir
Graphs.create_graph(pools, "Pools - FDP", "fdp")
```

```elixir
Graphs.create_graph(pools, "Pools - Linke", "linke")
```

## Party

```elixir
parties_df =
  Explorer.DataFrame.new(
    party: ["csu", "fw", "spd", "gruene", "fdp", "afd", "linke"],
    candiate1: [
      "Markus Söder",
      "Hubert Aiwanger",
      "Florian von Brunn",
      "Ludwig Hartmann",
      "Martin Hagen",
      "Katrin Ebner-Steiner",
      "Adelheid Rupp"
    ],
    candidate2: [nil, nil, nil, "Katharina Schulze", nil, "Martin Böhm", nil]
  )

Explorer.DataFrame.head(parties_df)
```

## Preprocessing

```elixir
p = Path.absname("mastodon/mastodon_bayernwahl2023.db")
```

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
db =
  Kino.start_child(
    {Adbc.Database, driver: :sqlite, uri: "file:mastodon/mastodon_bayernwahl2023.db"}
  )
```

```elixir
conn = Kino.start_child({Adbc.Connection, database: db})
Explorer.DataFrame.from_query(conn, "select * from toots", [])
```

## Classification

```elixir
{model, params} = AxonOnnx.import("./models/models/german_sentiment_model.onnx")
```

```elixir
{:ok, vocab_string} = File.read("./models/models/vocab.json")
{:ok, vocab_map} = Jason.decode(vocab_string)
```

```elixir
# Tokenize
input_text = "Ein scheiß Film"
token_list = Enum.map(String.split(input_text, " "), fn x -> Map.get(vocab_map, x, 0) end)
token_tensor = Nx.tensor(List.duplicate(0, 512 - length(token_list)))
token_tensor = Nx.concatenate([Nx.tensor(token_list), token_tensor])
```

```elixir
{init_fn, predict_fn} = Axon.build(model)
```

```elixir
import Nx.Defn

defn poltical_score(prediction) do
  one_hot = ** prediction / Nx.sum(2 ** prediction)
  5 * (one_hot[0][0] - one_hot[0][1])
end

prediction = predict_fn.(params, token_tensor)
poltical_score(prediction)
```

<!-- livebook:{"attrs":{"compiler":"exla","sequence_length":100,"task_id":"text_classification","top_k":null,"variant_id":"xlm_roberta_language_detection"},"chunks":[[0,359],[361,496]],"kind":"Elixir.KinoBumblebee.TaskCell","livebook_object":"smart_cell"} -->

```elixir
{:ok, model_info} = Bumblebee.load_model({:hf, "papluca/xlm-roberta-base-language-detection"})

{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "papluca/xlm-roberta-base-language-detection"})

serving =
  Bumblebee.Text.text_classification(model_info, tokenizer,
    compile: [batch_size: 1, sequence_length: 100],
    defn_options: [compiler: EXLA]
  )

text_input = Kino.Input.textarea("Text", default: "La casa de papel")
form = Kino.Control.form([text: text_input], submit: "Run")
frame = Kino.Frame.new()

Kino.listen(form, fn %{data: %{text: text}} ->
  Kino.Frame.render(frame, Kino.Text.new("Running..."))
  output = Nx.Serving.run(serving, text)

  output.predictions
  |> Enum.map(&{&1.label, &1.score})
  |> Kino.Bumblebee.ScoredList.new()
  |> then(&Kino.Frame.render(frame, &1))
end)

Kino.Layout.grid([form, frame], boxed: true, gap: 16)
```
